import numpy as np
from ase.data import atomic_numbers
from scipy import linalg
from sklearn.metrics.pairwise import euclidean_distances, cosine_distances

def div_mat(mat, n):
    split_mat = []
    div_1, mod_1 = divmod(mat.shape[0], n)
    div_2, mod_2 = divmod(mod_1, div_1)
    for i in range(mod_2):
        split_mat.append(mat[i*(n+div_2+1):(i+1)*(n+div_2+1),:])
    begin_index = mod_2 * (n+div_2+1)
    for i in range(div_1-mod_2):
        split_mat.append(mat[begin_index + i*(n+div_2):begin_index + (i+1)*(n+div_2),:])
    return split_mat

# function.data file is generated by n2p2. It can also be replaced by learned features in GNNs.
def read_symfunc(symfunc='function.data', inputnn='input.nn'):
    # define dict
    emap = {}
    for line in open(inputnn, 'r'):
        if line.startswith('number_of_elements '):
            num_elements = int(line.split()[1])
        if line.startswith('elements '):
            elements = line.split()
    for e in elements[1:1+num_elements]:
        emap[e] = atomic_numbers[e]
    sfs = {}
    for key in emap.keys():
        sfs[key] = []

    # readlines
    with open(symfunc) as f:
        lines = f.readlines()
    i, j = 0, 0
    line_num = len(lines)
    while j < line_num:
        atoms_num = int(lines[j].rstrip())
        for k, line in enumerate(lines[j+1:j+atoms_num+1]):
            tmp_line = line.rstrip().split()
            for key, val in emap.items():                
                if tmp_line[0] == str(val):
                    # element, image index, atom index, symmetry function values
                    sfs[key].append([int(tmp_line[0])] + [i] + [k] + list(map(float, tmp_line[1:])))
        j += (atoms_num+2)
        i += 1

    for key in sfs.keys():
        sfs[key] = np.asarray(sfs[key], dtype=float)
    for i, (key, val) in enumerate(emap.items()):
        print('No.{0} element: {1}  Atomic number: {2} Center atoms number: {3} Symfunc number: {4}'.format(i+1, key, val, sfs[key].shape[0], sfs[key].shape[1]-3))
    return sfs

def CUR_decomposition_row(X, alpha=0.1, beta=0.1):
    # initialize W, W_T, Z, A_1, A_2, rho_1, rho_2, convergence criterion epsilon
    n, m = X.shape
    W = np.zeros((m,n))
    Z = A_1 = np.zeros((n,n)) # XW for maximizing distances between 
    W_T = A_2 = np.zeros((n,m))
    rho_1 = rho_2 = 1E-6
    max_rho = 1E+10
    tau = 1.1
    epsilon = 1E-3
    k = 0

    # calculate theta_2, Q, T, 
    theta_2, Q = linalg.eigh(X.T @ X)
    theta_2 = theta_2.reshape(-1,1)
    T =  1/(euclidean_distances(X) + 1E-6)  # add a regulization term 0.001     # use Euclidean distance for reference structures selection
    obj_func = linalg.norm(X-X@W@X)**2 + alpha*np.sum(linalg.norm(W.T, axis=1)) + beta*linalg.norm(T*(X@W), ord=1)
    while True:
        # minimize W
        M = 2*X @ X.T + rho_1 * np.eye(n,n)          
        theta_1, P = linalg.eigh(M)
        theta_1 = theta_1.reshape(1,-1)
        H = 2*X.T@X@X.T + rho_1*X.T@(Z-A_1/rho_1) + rho_2*(W_T-A_2/rho_2).T
        Y= Q.T@H@P / (theta_2@theta_1 + rho_2)
        W = Q@Y@P.T

        # minimize W_T
        S2 = W.T + A_2/rho_2
        W_T = np.zeros((n,m))
        S2_row_norm = linalg.norm(S2, axis=1)
        non_zero_indexs = np.where(S2_row_norm > alpha/rho_2)
        W_T[non_zero_indexs] = np.diag(1-alpha/(rho_2*S2_row_norm[non_zero_indexs])) @ S2[non_zero_indexs] 

        # minimize Z
        S1 =  X@W + A_1/rho_1
        Z = np.maximum(np.abs(S1)-beta*T/rho_1, 0) * np.sign(S1)

        # updata multipliers and parameters
        A_1 = A_1 + rho_1*(X@W-Z) 
        A_2 = A_2 + rho_2*(W.T - W_T)
        rho_1 = min(tau*rho_1, max_rho)
        rho_2 = min(tau*rho_2, max_rho)              
        new_obj_func = linalg.norm(X-X@W@X)**2 + alpha*np.sum(linalg.norm(W.T, axis=1)) + beta*linalg.norm(T*(X@W), 1)
        
        # check the convergence conditions
        criteria = np.asarray([linalg.norm(X@W-Z, np.inf), linalg.norm(W.T-W_T, np.inf), abs((new_obj_func-obj_func)/obj_func)], dtype=float)
        if np.all(criteria < epsilon):
            break
        obj_func = new_obj_func
        k += 1
        if k > 10000:
            break
    return W, criteria

def CUR_decomposition_col(X, alpha=0.1, beta=0.1):
    # initialize W, W_T, Z, A_1, A_2, rho_1, rho_2, convergence criterion epsilon
    X = X.T
    n, m = X.shape
    W = np.zeros((m,n))
    Z = A_1 = np.zeros((n,n)) # XW for maximizing distances between 
    W_T = A_2 = np.zeros((n,m))
    rho_1 = rho_2 = 1E-6
    max_rho = 1E+10
    tau = 1.1
    epsilon = 1E-3
    k = 0

    # calculate theta_2, Q, T, 
    theta_2, Q = linalg.eigh(X.T @ X)
    theta_2 = theta_2.reshape(-1,1)
    T = 1 / (cosine_distances(X) + 0.001)  # add a regulization term 0.001     # use Euclidean distance for reference structures selection
    obj_func = linalg.norm(X-X@W@X)**2 + alpha*np.sum(linalg.norm(W.T, axis=1)) + beta*linalg.norm(T*(X@W), ord=1)
    while True:
        # minimize W
        M = 2*X @ X.T + rho_1 * np.eye(n,n)
        theta_1, P = linalg.eigh(M)
        theta_1 = theta_1.reshape(1,-1)
        H = 2*X.T@X@X.T + rho_1*X.T@(Z-A_1/rho_1) + rho_2*(W_T-A_2/rho_2).T
        Y= Q.T@H@P / (theta_2@theta_1 + rho_2)
        W = Q@Y@P.T

        # minimize W_T
        S2 = W.T + A_2/rho_2
        W_T = np.zeros((n,m))
        S2_row_norm = linalg.norm(S2, axis=1)
        non_zero_indexs = np.where(S2_row_norm > alpha/rho_2)
        W_T[non_zero_indexs] = np.diag(1-alpha/(rho_2*S2_row_norm[non_zero_indexs])) @ S2[non_zero_indexs] 

        # minimize Z
        S1 =  X@W + A_1/rho_1
        Z = np.maximum(np.abs(S1)-beta*T/rho_1, 0) * np.sign(S1)

        # updata multipliers and parameters
        A_1 = A_1 + rho_1*(X@W-Z) 
        A_2 = A_2 + rho_2*(W.T - W_T)
        rho_1 = min(tau*rho_1, max_rho)
        rho_2 = min(tau*rho_2, max_rho)              
        new_obj_func = linalg.norm(X-X@W@X)**2 + alpha*np.sum(linalg.norm(W.T, axis=1)) + beta*linalg.norm(T*(X@W), 1)
        
        # check the convergence conditions
        criteria = np.asarray([linalg.norm(X@W-Z, np.inf), linalg.norm(W.T-W_T, np.inf), abs((new_obj_func-obj_func)/obj_func)], dtype=float)
        if np.all(criteria < epsilon):
            break
        obj_func = new_obj_func
        k += 1
        if k > 10000:
            break
    return W, criteria

def joint_CUR_decomposition(X, alpha=0.1, beta=0.1, gamma=1):
    # initialize W, W_T, Z, A_1, A_2, rho_1, rho_2, convergence criterion epsilon
    n, m = X.shape
    W = np.zeros((m,n))
    Z = A_1 = np.zeros((m,m)) # WX for maximizing cosine distance between columns
    W_0 = A_2 = np.zeros((m,n))
    W_T = A_3 = np.zeros((n,m))
    rho_1 = rho_2 = rho_3  = 1E-6
    max_rho = 1E+10
    tau = 1.1
    epsilon = 1E-3
    k = 0

    # calculate theta_2, Q, T, 
    theta_2, Q = linalg.eigh(X @ X.T)
    theta_2 = theta_2.reshape(1,-1)
    T =  1/(cosine_distances(X.T) + 0.0001)  # add a regulization term 0.001     # use Euclidean distance for reference structures selection
    obj_func = linalg.norm(X-X@W@X)**2 + alpha*np.sum(linalg.norm(W, axis=1)) + beta*np.sum(linalg.norm(W.T, axis=1)) + gamma*linalg.norm(T*(W@X), ord=1)
    while True:
        # minimize W
        M = 2*X.T @ X + rho_1 * np.eye(m,m)
        theta_1, P = linalg.eigh(M)
        theta_1 = theta_1.reshape(-1,1)
        H = 2*X.T@X@X.T + rho_1*(Z-A_1/rho_1)@X.T + rho_2*(W_0-A_2/rho_2) + rho_3*(W_T-A_3/rho_3).T
        Y = P.T@H@Q / (theta_1@theta_2 + rho_2 + rho_3)
        W = P@Y@Q.T

        # minimize W_0
        S2 = W + A_2/rho_2
        W_0 = np.zeros((m,n))
        S2_row_norm = linalg.norm(S2, axis=1)
        non_zero_indexs = np.where(S2_row_norm > alpha/rho_2)
        W_0[non_zero_indexs] = np.diag(1-alpha/(rho_2*S2_row_norm[non_zero_indexs])) @ S2[non_zero_indexs]
        
        # minimize W_T
        S3 = W.T + A_3/rho_3
        W_T = np.zeros((n,m))
        S3_row_norm = linalg.norm(S3, axis=1)
        non_zero_indexs = np.where(S3_row_norm > beta/rho_3)
        W_T[non_zero_indexs] = np.diag(1-beta/(rho_3*S3_row_norm[non_zero_indexs])) @ S3[non_zero_indexs] 

        # minimize Z
        S1 =  W@X + A_1/rho_1
        Z = np.maximum(np.abs(S1)-gamma*T/rho_1, 0) * np.sign(S1)

        # updata multipliers and parameters
        A_1 = A_1 + rho_1*(W@X-Z) 
        A_2 = A_2 + rho_2*(W_0 - W_0)
        A_3 = A_3 + rho_3*(W_T - W_T)
        rho_1 = min(tau*rho_1, max_rho)
        rho_2 = min(tau*rho_2, max_rho)    
        rho_3 = min(tau*rho_3, max_rho)          
        new_obj_func = linalg.norm(X-X@W@X)**2 + alpha*np.sum(linalg.norm(W, axis=1)) + beta*np.sum(linalg.norm(W.T, axis=1)) + gamma*linalg.norm(T*(W@X), ord=1)
        
        # check the convergence conditions
        criteria = np.asarray([linalg.norm(W@X-Z, np.inf), linalg.norm(W-W_0, np.inf), linalg.norm(W.T-W_T, np.inf), abs((new_obj_func-obj_func)/obj_func)], dtype=float)
        if np.all(criteria < epsilon):
            break
        obj_func = new_obj_func
        k += 1
        if k > 10000:
            break
    return W, criteria
